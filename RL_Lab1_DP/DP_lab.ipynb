{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reinforcement Learning - Dynamic Programming\n",
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dp_autograde.py file into codegrade.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# This cell imports %%execwritefile command (executes cell and writes it into file). \n",
    "# All cells that start with %%execwritefile should be in dp_autograde.py file after running all cells.\n",
    "from custommagics import CustomMagics\n",
    "get_ipython().register_magics(CustomMagics)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%%execwritefile dp_autograde.py\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting dp_autograde.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Policy Evaluation (1 point)\n",
    "In this exercise we will evaluate a policy, e.g. find the value function of a policy. The problem we consider is the gridworld from Example 4.1 in the book. The environment is implemented as `GridworldEnv`, which is a subclass of the `Env` class from [OpenAI Gym](https://github.com/openai/gym). This means that we can interact with the environment. We can look at the documentation to see how we can interact with the environment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from gridworld import GridworldEnv\n",
    "env = GridworldEnv()\n",
    "# Lets see what this is\n",
    "?env"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[0;31mType:\u001b[0m        GridworldEnv\n",
      "\u001b[0;31mString form:\u001b[0m <GridworldEnv instance>\n",
      "\u001b[0;31mFile:\u001b[0m        ~/UvA_AI/RL/RL_Lab1_DP/gridworld.py\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "Grid World environment from Sutton's Reinforcement Learning book chapter 4.\n",
      "You are an agent on an MxN grid and your goal is to reach the terminal\n",
      "state at the top left or the bottom right corner.\n",
      "\n",
      "For example, a 4x4 grid looks as follows:\n",
      "\n",
      "T  o  o  o\n",
      "o  x  o  o\n",
      "o  o  o  o\n",
      "o  o  o  T\n",
      "\n",
      "x is your position and T are the two terminal states.\n",
      "\n",
      "You can take actions in each direction (UP=0, RIGHT=1, DOWN=2, LEFT=3).\n",
      "Actions going off the edge leave you in your current state.\n",
      "You receive a reward of -1 at each step until you reach a terminal state.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# To have a quick look into the code\n",
    "??env"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[0;31mType:\u001b[0m        GridworldEnv\n",
      "\u001b[0;31mString form:\u001b[0m <GridworldEnv instance>\n",
      "\u001b[0;31mFile:\u001b[0m        ~/UvA_AI/RL/RL_Lab1_DP/gridworld.py\n",
      "\u001b[0;31mSource:\u001b[0m     \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mGridworldEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscreteEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m    Grid World environment from Sutton's Reinforcement Learning book chapter 4.\u001b[0m\n",
      "\u001b[0;34m    You are an agent on an MxN grid and your goal is to reach the terminal\u001b[0m\n",
      "\u001b[0;34m    state at the top left or the bottom right corner.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For example, a 4x4 grid looks as follows:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    T  o  o  o\u001b[0m\n",
      "\u001b[0;34m    o  x  o  o\u001b[0m\n",
      "\u001b[0;34m    o  o  o  o\u001b[0m\n",
      "\u001b[0;34m    o  o  o  T\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    x is your position and T are the two terminal states.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    You can take actions in each direction (UP=0, RIGHT=1, DOWN=2, LEFT=3).\u001b[0m\n",
      "\u001b[0;34m    Actions going off the edge leave you in your current state.\u001b[0m\n",
      "\u001b[0;34m    You receive a reward of -1 at each step until you reach a terminal state.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'render.modes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ansi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shape argument must be a list/tuple of length 2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mnS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mnA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mMAX_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mMAX_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'multi_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterindex\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_index\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mis_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnS\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# We're stuck in a terminal state\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUP\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRIGHT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDOWN\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLEFT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Not a terminal state\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mns_up\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mMAX_X\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mns_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMAX_X\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mns_down\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMAX_Y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMAX_X\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mns_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUP\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_up\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns_up\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRIGHT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDOWN\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_down\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns_down\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLEFT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miternext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Initial state distribution is uniform\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0misd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnS\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# We expose the model of the environment for educational purposes\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# This should not be used in any model-free learning algorithm\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGridworldEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ansi'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'multi_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterindex\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_index\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" x \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnS\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" T \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" o \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moutfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0moutfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miternext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we want to evaluate a policy by using Dynamic Programming. For more information, see the [Intro to RL](https://drive.google.com/open?id=1opPSz5AZ_kVa1uWOdOiveNiBFiEOHjkG) book, section 4.1. This algorithm requires knowledge of the problem dynamics in the form of the transition probabilities $p(s',r|s,a)$. In general these are not available, but for our gridworld we know the dynamics and these can be accessed as `env.P`. Note that we do not need to use a discount_factor for episodic tasks but make sure your implementation can handle this correctly!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Take a moment to figure out what P represents. \n",
    "# Note that this is a deterministic environment. \n",
    "# What would a stochastic environment look like?\n",
    "env.P"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {0: [(1.0, 0, 0.0, True)],\n",
       "  1: [(1.0, 0, 0.0, True)],\n",
       "  2: [(1.0, 0, 0.0, True)],\n",
       "  3: [(1.0, 0, 0.0, True)]},\n",
       " 1: {0: [(1.0, 1, -1.0, False)],\n",
       "  1: [(1.0, 2, -1.0, False)],\n",
       "  2: [(1.0, 5, -1.0, False)],\n",
       "  3: [(1.0, 0, -1.0, True)]},\n",
       " 2: {0: [(1.0, 2, -1.0, False)],\n",
       "  1: [(1.0, 3, -1.0, False)],\n",
       "  2: [(1.0, 6, -1.0, False)],\n",
       "  3: [(1.0, 1, -1.0, False)]},\n",
       " 3: {0: [(1.0, 3, -1.0, False)],\n",
       "  1: [(1.0, 3, -1.0, False)],\n",
       "  2: [(1.0, 7, -1.0, False)],\n",
       "  3: [(1.0, 2, -1.0, False)]},\n",
       " 4: {0: [(1.0, 0, -1.0, True)],\n",
       "  1: [(1.0, 5, -1.0, False)],\n",
       "  2: [(1.0, 8, -1.0, False)],\n",
       "  3: [(1.0, 4, -1.0, False)]},\n",
       " 5: {0: [(1.0, 1, -1.0, False)],\n",
       "  1: [(1.0, 6, -1.0, False)],\n",
       "  2: [(1.0, 9, -1.0, False)],\n",
       "  3: [(1.0, 4, -1.0, False)]},\n",
       " 6: {0: [(1.0, 2, -1.0, False)],\n",
       "  1: [(1.0, 7, -1.0, False)],\n",
       "  2: [(1.0, 10, -1.0, False)],\n",
       "  3: [(1.0, 5, -1.0, False)]},\n",
       " 7: {0: [(1.0, 3, -1.0, False)],\n",
       "  1: [(1.0, 7, -1.0, False)],\n",
       "  2: [(1.0, 11, -1.0, False)],\n",
       "  3: [(1.0, 6, -1.0, False)]},\n",
       " 8: {0: [(1.0, 4, -1.0, False)],\n",
       "  1: [(1.0, 9, -1.0, False)],\n",
       "  2: [(1.0, 12, -1.0, False)],\n",
       "  3: [(1.0, 8, -1.0, False)]},\n",
       " 9: {0: [(1.0, 5, -1.0, False)],\n",
       "  1: [(1.0, 10, -1.0, False)],\n",
       "  2: [(1.0, 13, -1.0, False)],\n",
       "  3: [(1.0, 8, -1.0, False)]},\n",
       " 10: {0: [(1.0, 6, -1.0, False)],\n",
       "  1: [(1.0, 11, -1.0, False)],\n",
       "  2: [(1.0, 14, -1.0, False)],\n",
       "  3: [(1.0, 9, -1.0, False)]},\n",
       " 11: {0: [(1.0, 7, -1.0, False)],\n",
       "  1: [(1.0, 11, -1.0, False)],\n",
       "  2: [(1.0, 15, -1.0, True)],\n",
       "  3: [(1.0, 10, -1.0, False)]},\n",
       " 12: {0: [(1.0, 8, -1.0, False)],\n",
       "  1: [(1.0, 13, -1.0, False)],\n",
       "  2: [(1.0, 12, -1.0, False)],\n",
       "  3: [(1.0, 12, -1.0, False)]},\n",
       " 13: {0: [(1.0, 9, -1.0, False)],\n",
       "  1: [(1.0, 14, -1.0, False)],\n",
       "  2: [(1.0, 13, -1.0, False)],\n",
       "  3: [(1.0, 12, -1.0, False)]},\n",
       " 14: {0: [(1.0, 10, -1.0, False)],\n",
       "  1: [(1.0, 15, -1.0, True)],\n",
       "  2: [(1.0, 14, -1.0, False)],\n",
       "  3: [(1.0, 13, -1.0, False)]},\n",
       " 15: {0: [(1.0, 15, 0.0, True)],\n",
       "  1: [(1.0, 15, 0.0, True)],\n",
       "  2: [(1.0, 15, 0.0, True)],\n",
       "  3: [(1.0, 15, 0.0, True)]}}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "%%execwritefile -a dp_autograde.py\n",
    "\n",
    "def policy_eval_v(policy, env, discount_factor=1.0, theta=0.00001):\n",
    "    \"\"\"\n",
    "    Evaluate a policy given an environment and a full description of the environment's dynamics.\n",
    "    \n",
    "    Args:\n",
    "        policy: [S, A] shaped matrix representing the policy.\n",
    "        env: OpenAI env. env.P represents the transition probabilities of the environment.\n",
    "            env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
    "            env.nS is a number of states in the environment. \n",
    "            env.nA is a number of actions in the environment.\n",
    "        theta: We stop evaluation once our value function change is less than theta for all states.\n",
    "        discount_factor: Gamma discount factor.\n",
    "    \n",
    "    Returns:\n",
    "        Vector of length env.nS representing the value function.\n",
    "    \"\"\"\n",
    "    # Start with an all 0 value function\n",
    "    V = np.zeros(env.nS)\n",
    "    # YOUR CODE HERE\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in range(env.nS):\n",
    "            v = V[s]\n",
    "            v_s = 0\n",
    "            for action, action_prob in enumerate(policy[s]):\n",
    "                for prob, next_state, reward, _ in env.P[s][action]:\n",
    "                    v_s += action_prob * (prob * (reward + discount_factor * V[next_state]))\n",
    "            V[s] = v_s\n",
    "            delta = max(delta, np.abs(v - V[s]))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return np.array(V)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Appending to dp_autograde.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Let's run your code, does it make sense?\n",
    "random_policy = np.ones([env.nS, env.nA]) / env.nA\n",
    "#random_policy = np.array([[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], dtype=int)\n",
    "V = policy_eval_v(random_policy, env)\n",
    "assert V.shape == (env.nS)\n",
    "V"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  0.        , -13.99993529, -19.99990698, -21.99989761,\n",
       "       -13.99993529, -17.9999206 , -19.99991379, -19.99991477,\n",
       "       -19.99990698, -19.99991379, -17.99992725, -13.99994569,\n",
       "       -21.99989761, -19.99991477, -13.99994569,   0.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def plot_gridworld_value(V):\n",
    "    plt.figure()\n",
    "    c = plt.pcolormesh(V, cmap='gray')\n",
    "    plt.colorbar(c)\n",
    "    plt.gca().invert_yaxis()  # In the array, first row = 0 is on top\n",
    "\n",
    "# Making a plot always helps\n",
    "plot_gridworld_value(V.reshape(env.shape))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. Policy Iteration (2 points)\n",
    "Using the policy evaluation algorithm we can implement policy iteration to find a good policy for this problem. Note that we do not need to use a discount_factor for episodic tasks but make sure your implementation can handle this correctly!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "%%execwritefile -a dp_autograde.py\n",
    "\n",
    "def policy_iter_v(env, policy_eval_v=policy_eval_v, discount_factor=1.0):\n",
    "    \"\"\"\n",
    "    Policy Iteration Algorithm. Iteratively evaluates and improves a policy\n",
    "    until an optimal policy is found.\n",
    "    \n",
    "    Args:\n",
    "        env: The OpenAI envrionment.\n",
    "        policy_eval_v: Policy Evaluation function that takes 3 arguments:\n",
    "            policy, env, discount_factor.\n",
    "        discount_factor: gamma discount factor.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (policy, V). \n",
    "        policy is the optimal policy, a matrix of shape [S, A] where each state s\n",
    "        contains a valid probability distribution over actions.\n",
    "        V is the value function for the optimal policy.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Start with a random policy\n",
    "    policy = np.ones([env.nS, env.nA]) / env.nA\n",
    "    # YOUR CODE HERE\n",
    "    while True:\n",
    "        V = policy_eval_v(policy, env, discount_factor)\n",
    "        policy_stable = True\n",
    "        for s in range(env.nS):\n",
    "            old_action = np.argmax(policy[s])\n",
    "            actions = np.zeros(env.nA)\n",
    "            for action, action_prob in enumerate(policy[s]):\n",
    "                for prob, next_state, reward, _ in env.P[s][action]:\n",
    "                    actions[action] += (prob * (reward + discount_factor * V[next_state]))\n",
    "            policy[s] = np.eye(env.nA)[np.argmax(actions)]\n",
    "            if np.argmax(policy[s]) != old_action:\n",
    "                policy_stable = False\n",
    "        if policy_stable:\n",
    "            break\n",
    "    return policy, V"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Appending to dp_autograde.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Let's see what it does\n",
    "policy, v = policy_iter_v(env, policy_eval_v)\n",
    "print(\"Policy Probability Distribution:\")\n",
    "print(policy)\n",
    "print(\"\")\n",
    "\n",
    "def print_grid_policy(policy, symbols=[\"^\", \">\", \"v\", \"<\"]):\n",
    "    symbols = np.array(symbols)\n",
    "    for row in policy:\n",
    "        print(\"\".join(symbols[row]))\n",
    "\n",
    "print(\"Reshaped Grid Policy (0=up, 1=right, 2=down, 3=left):\")\n",
    "print(np.reshape(np.argmax(policy, axis=1), env.shape))\n",
    "print_grid_policy(np.reshape(np.argmax(policy, axis=1), env.shape))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Value Function:\")\n",
    "print(v)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Reshaped Grid Value Function:\")\n",
    "print(v.reshape(env.shape))\n",
    "print(\"\")\n",
    "\n",
    "plot_gridworld_value(v.reshape(env.shape))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Policy Probability Distribution:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "\n",
      "Reshaped Grid Policy (0=up, 1=right, 2=down, 3=left):\n",
      "[[0 3 3 2]\n",
      " [0 0 0 2]\n",
      " [0 0 1 2]\n",
      " [0 1 1 0]]\n",
      "^<<v\n",
      "^^^v\n",
      "^^>v\n",
      "^>>^\n",
      "\n",
      "Value Function:\n",
      "[ 0. -1. -2. -3. -1. -2. -3. -2. -2. -3. -2. -1. -3. -2. -1.  0.]\n",
      "\n",
      "Reshaped Grid Value Function:\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. Q-value Iteration (3 points)\n",
    "In this exercise you will implement the value iteration algorithm. However, because this algorithm is quite similar to the ones you implemented previously, we will spice things up a bit and use Q-values instead. Thus instead of using Bellman optimality equations for V you will use Bellman equations for Q. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "%%execwritefile -a dp_autograde.py\n",
    "\n",
    "def value_iter_q(env, theta=0.0001, discount_factor=1.0):\n",
    "    \"\"\"\n",
    "    Q-value Iteration Algorithm.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI env. env.P represents the transition probabilities of the environment.\n",
    "            env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
    "            env.nS is a number of states in the environment. \n",
    "            env.nA is a number of actions in the environment.\n",
    "        theta: We stop evaluation once our value function change is less than theta for all state-action pairs.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (policy, Q) of the optimal policy and the optimal Q-value function.        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Start with an all 0 Q-value function\n",
    "    Q = np.zeros((env.nS, env.nA))\n",
    "    # YOUR CODE HERE\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in range(env.nS):\n",
    "            for a in range(env.nA):\n",
    "                v = Q[s][a]\n",
    "                v_q = 0\n",
    "                for prob, next_state, reward, _ in env.P[s][a]:\n",
    "                    best_action = np.argmax(Q[next_state])\n",
    "                    v_q += prob * (reward + discount_factor * Q[next_state][best_action])\n",
    "                Q[s][a] = v_q\n",
    "                delta = max(delta, np.abs(v - Q[s][a]))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    \n",
    "    policy = np.zeros([env.nS, env.nA])\n",
    "    for s in range(env.nS):\n",
    "        policy[s] = np.eye(env.nA)[np.argmax(Q[s])]\n",
    "    return policy, Q"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Appending to dp_autograde.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Let's see what it does\n",
    "policy, Q = value_iter_q(env)\n",
    "print(\"Policy Probability Distribution:\")\n",
    "print(policy)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Reshaped Grid Policy (0=up, 1=right, 2=down, 3=left):\")\n",
    "print(np.reshape(np.argmax(policy, axis=1), env.shape))\n",
    "print_grid_policy(np.reshape(np.argmax(policy, axis=1), env.shape))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Q Function:\")\n",
    "print(Q)\n",
    "print(\"\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Policy Probability Distribution:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "\n",
      "Reshaped Grid Policy (0=up, 1=right, 2=down, 3=left):\n",
      "[[0 3 3 2]\n",
      " [0 0 0 2]\n",
      " [0 0 1 2]\n",
      " [0 1 1 0]]\n",
      "^<<v\n",
      "^^^v\n",
      "^^>v\n",
      "^>>^\n",
      "\n",
      "Q Function:\n",
      "[[ 0.  0.  0.  0.]\n",
      " [-2. -3. -3. -1.]\n",
      " [-3. -4. -4. -2.]\n",
      " [-4. -4. -3. -3.]\n",
      " [-1. -3. -3. -2.]\n",
      " [-2. -4. -4. -2.]\n",
      " [-3. -3. -3. -3.]\n",
      " [-4. -3. -2. -4.]\n",
      " [-2. -4. -4. -3.]\n",
      " [-3. -3. -3. -3.]\n",
      " [-4. -2. -2. -4.]\n",
      " [-3. -2. -1. -3.]\n",
      " [-3. -3. -4. -4.]\n",
      " [-4. -2. -3. -4.]\n",
      " [-3. -1. -2. -3.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# As you can see, the visualization of the Q function is quite clumsy and is not that easy to check \n",
    "# that all values make sense. However, you can easily create a V function from Q and policy to double\n",
    "# check that the values are what you would expect.\n",
    "V = np.sum(Q, axis=1)\n",
    "# Making a plot always helps\n",
    "plot_gridworld_value(V.reshape(env.shape))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dp_autograde.py file into codegrade.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('rlcourse': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "interpreter": {
   "hash": "a2c9532d598ba9df1972d88801a9d1e49c2eb1401e1892733205fb427171d76e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}